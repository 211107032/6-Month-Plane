{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ede8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca67eff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "url = pd.read_csv(\"titanic_ dataset_final.csv\")\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8dd83bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e4254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Collecting pydantic>=2.9 (from ollama)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\milind rajput\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic>=2.9->ollama)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9->ollama)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.0 MB 660.6 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/2.0 MB 2.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.0 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/2.0 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 8.3 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.9/43.9 kB ? eta 0:00:00\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, typing-inspection, pydantic-core, pydantic, ollama\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed ollama-0.5.1 pydantic-2.11.7 pydantic-core-2.33.2 typing-extensions-4.14.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50feceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ AI-Generated Insights:\n",
      " Okay, let's analyze this dataset and provide some insights.  This dataset appears to be about passenger information, likely from an airline or travel company. Here's a breakdown of what we can observe, grouped into categories:\n",
      "\n",
      "**1. Key Summary Statistics:**\n",
      "\n",
      "* **Overall Survival Rate:**  The overall survival rate is quite high â€“ 89% across all classes. This is a strong positive indicator.\n",
      "* **Passenger Count:** There are 891 passengers in total.\n",
      "* **Mean Survival:** The average survival rate across all passengers is 446. This is a significant positive outcome.\n",
      "* **Standard Deviation:** The standard deviation is relatively low (257.35), suggesting that differences in survival rates are not drastically large.\n",
      "* **Minimum & Maximum Values:** The minimum survival rate is 1.0, and the maximum is 891.\n",
      "\n",
      "**2. Distribution Analysis - Class-Specific:**\n",
      "\n",
      "* **Pclass (Passenger Class):**  The distribution is fairly even across all classes. There's no significant skew in the survival rates.\n",
      "* **SibSp (Number of Siblings/Spouses):** The distribution of SibSp is a little more skewed to the left (higher values).  This suggests a higher probability of passengers with multiple family members onboard.\n",
      "* **Parch (Number of Parents/Children):**  Similar to SibSp, the distribution of Parch shows a slight skew to the left.\n",
      "* **Fare:** The distribution of fares is generally uniform, with a moderate range.\n",
      "\n",
      "**3. Insights and Potential Interpretations:**\n",
      "\n",
      "* **High Survival Rate is a Major Positive:** The 89% survival rate is the most compelling insight.  It points to a generally well-managed and safe travel experience.\n",
      "* **SibSp/Parch Influence:** The skew in the SibSp/Parch distribution suggests that passengers with a lot of family members on board (i.e., a higher number of Siblings/Spouses/Parents/Children) are more likely to survive. This might be a contributing factor to the overall survival rate, potentially due to increased risk of accidents or other issues.\n",
      "* **Pclass Might Play a Role:**  While the distribution is generally similar across classes, a possible (though requiring more data) correlation could exist. Perhaps higherPclass passengers have a slightly higher survival rate. However, this needs to be confirmed through further analysis.\n",
      "* **Fare Influence:** The Fare could also be a factor, but the distribution is relatively uniform.\n",
      "\n",
      "**4. Possible Follow-Up Questions & Further Analysis:**\n",
      "\n",
      "* **What is the distribution of SibSp and Parch by Class?** A visualization (like a box plot) could reveal whether the skew is consistent across different passenger classes.\n",
      "* **Is there a relationship between Fare and Survival?**  We could investigate if passengers with higher fares are slightly less likely to survive.\n",
      "* **Explore other variables:**  Adding data on other variables (e.g., age, gender, route) could provide more nuanced insights.\n",
      "* **Time Series Analysis:** If this data represents a longitudinal dataset (where observations are made over time), we could analyze trends over time to see if survival rates are changing.\n",
      "* **Segment Analysis:**  Can we segment passengers by their combination of Pclass, SibSp, and Parch to identify specific groups that have higher survival rates or are more vulnerable?\n",
      "\n",
      "\n",
      "**In conclusion, this dataset offers a strong indication of a safe and relatively successful travel experience, with a particularly high survival rate.  Further investigation would be valuable to understand the factors contributing to this outcome.**\n",
      "\n",
      "---\n",
      "\n",
      "To provide even more tailored analysis, could you tell me:\n",
      "\n",
      "*   What is the context of this dataset? (e.g., airline data, travel agency data, etc.)\n",
      "*   Are there any specific questions you'd like me to focus on?\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_insights(df_summary):\n",
    "    prompt = f\"Analyze the dataset summary and provide insights:\\n\\n{df_summary}\"\n",
    "    response = ollama.chat(model=\"gemma3:1b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Generate AI Insights\n",
    "summary = url.describe().to_string()\n",
    "insights = generate_insights(summary)\n",
    "\n",
    "print(\"\\nðŸ”¹ AI-Generated Insights:\\n\", insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6719f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://43ee1b28073da4ba1e.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://43ee1b28073da4ba1e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def eda_analysis(file):\n",
    "    df = pd.read_csv(file.name)\n",
    "    summary = df.describe().to_string()\n",
    "    insights = generate_insights(summary)\n",
    "    return insights\n",
    "\n",
    "# Create Web Interface\n",
    "demo = gr.Interface(fn=eda_analysis, inputs=\"file\", outputs=\"text\", title=\"AI-Powered EDA with Gemma\")\n",
    "\n",
    "# Launch App\n",
    "demo.launch(share=True)  # Use share=True for Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ebeab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
